{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string, random\n",
    "\n",
    "#packages\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "# LDA Model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "\n",
    "#sklearn & gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Building Question Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>ABBREVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5447</td>\n",
       "      <td>What 's the shape of a camel 's spine ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5448</td>\n",
       "      <td>What type of currency is used in China ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5449</td>\n",
       "      <td>What is the temperature today ?</td>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>What is the temperature for cooking ?</td>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5451</td>\n",
       "      <td>What currency is used in Australia ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5452 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions         class\n",
       "0     How did serfdom develop in and then leave Russ...   DESCRIPTION\n",
       "1      What films featured the character Popeye Doyle ?        ENTITY\n",
       "2     How can I find a list of celebrities ' real na...   DESCRIPTION\n",
       "3     What fowl grabs the spotlight after the Chines...        ENTITY\n",
       "4                       What is the full form of .com ?  ABBREVIATION\n",
       "...                                                 ...           ...\n",
       "5447            What 's the shape of a camel 's spine ?        ENTITY\n",
       "5448           What type of currency is used in China ?        ENTITY\n",
       "5449                    What is the temperature today ?       NUMERIC\n",
       "5450              What is the temperature for cooking ?       NUMERIC\n",
       "5451               What currency is used in Australia ?        ENTITY\n",
       "\n",
       "[5452 rows x 2 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"Question_Classification_Dataset.csv\")\n",
    "training_data = training_data[[\"Questions\", \"Category0\"]]\n",
    "training_data = training_data.rename(columns={\"Category0\": \"class\"})\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_tdm(df, specific_class):\n",
    "    D_docs = [row['Questions'] for index,row in training_data.iterrows() if row['class'] == specific_class]\n",
    "\n",
    "\n",
    "    vec_D = CountVectorizer()\n",
    "    X_D = vec_D.fit_transform(D_docs)\n",
    "    tdm_D = pd.DataFrame(X_D.toarray(), columns=vec_D.get_feature_names())\n",
    "\n",
    "    return tdm_D, vec_D, X_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_D, vec_D, X_D  = produce_tdm(training_data, \"DESCRIPTION\")\n",
    "tdm_E, vec_E, X_E = produce_tdm(training_data, \"ENTITY\")\n",
    "tdm_A, vec_A, X_A = produce_tdm(training_data, \"ABBREVIATION\")\n",
    "tdm_H, vec_H, X_H = produce_tdm(training_data, \"HUMAN\")\n",
    "tdm_N, vec_N, X_N = produce_tdm(training_data, \"NUMERIC\")\n",
    "tdm_L, vec_L, X_L = produce_tdm(training_data, \"LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_freq(vec, X):\n",
    "    word_list = vec.get_feature_names()\n",
    "    count_list = X.toarray().sum(axis=0) \n",
    "    freq = dict(zip(word_list,count_list))\n",
    "    freq\n",
    "\n",
    "    return freq, count_list, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_D, count_list_D, word_list_D = produce_freq(vec_D, X_D)\n",
    "freq_E, count_list_E, word_list_E = produce_freq(vec_E, X_E)\n",
    "freq_A, count_list_A, word_list_A = produce_freq(vec_A, X_A)\n",
    "freq_H, count_list_H, word_list_H = produce_freq(vec_H, X_H)\n",
    "freq_N, count_list_N, word_list_N = produce_freq(vec_N, X_N)\n",
    "freq_L, count_list_L, word_list_L = produce_freq(vec_L, X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(count_list, word_list):\n",
    "    prob = []\n",
    "    for count in count_list:\n",
    "        prob.append(count/len(word_list))\n",
    "    return dict(zip(word_list, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_D = get_prob(count_list_D, word_list_D)\n",
    "prob_E = get_prob(count_list_E, word_list_E)\n",
    "prob_A = get_prob(count_list_A, word_list_A)\n",
    "prob_H = get_prob(count_list_H, word_list_H)\n",
    "prob_N = get_prob(count_list_N, word_list_N)\n",
    "prob_L = get_prob(count_list_L, word_list_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8412"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [row['Questions'] for index,row in training_data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(docs)\n",
    "\n",
    "total_features = len(vec.get_feature_names())\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_D = count_list_D.sum(axis=0)\n",
    "total_cnts_features_E = count_list_E.sum(axis=0)\n",
    "total_cnts_features_A = count_list_A.sum(axis=0)\n",
    "total_cnts_features_H = count_list_H.sum(axis=0)\n",
    "total_cnts_features_N = count_list_N.sum(axis=0)\n",
    "total_cnts_features_L = count_list_L.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_with_qns(new_word_list, freq, total_cnts_features, total_features):\n",
    "    prob_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq.keys():\n",
    "            count = freq[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    output = dict(zip(new_word_list,prob_with_ls))\n",
    "    value_list = output.values()\n",
    "    value_list\n",
    "    \n",
    "    prob = 1\n",
    "    for each in value_list:\n",
    "        prob *= each\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_qns(qns):\n",
    "    new_word_list = word_tokenize(qns)\n",
    "    \n",
    "    prob_D = get_prob_with_qns(new_word_list, freq_D, total_cnts_features_D, total_features)\n",
    "    prob_E = get_prob_with_qns(new_word_list, freq_E, total_cnts_features_E, total_features)\n",
    "    prob_A = get_prob_with_qns(new_word_list, freq_A, total_cnts_features_A, total_features)\n",
    "    prob_H = get_prob_with_qns(new_word_list, freq_H, total_cnts_features_H, total_features)\n",
    "    prob_N = get_prob_with_qns(new_word_list, freq_N, total_cnts_features_N, total_features)\n",
    "    prob_L = get_prob_with_qns(new_word_list, freq_L, total_cnts_features_L, total_features)\n",
    "\n",
    "    prob = [prob_D, prob_E, prob_A, prob_H, prob_N, prob_L]\n",
    "    classes = [\"DESCRIPTION\", \"ENTITY\", \"ABBREVIATION\", 'HUMAN', \"NUMERIC\", \"LOCATION\"]\n",
    "    return(classes[prob.index(max(prob))], max(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 1.2506703038627668e-14)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much is the book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOCATION', 2.135747124966801e-08)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('where is singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HUMAN', 1.777338870239113e-08)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('who is beyonce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DESCRIPTION', 1.7397241521486881e-13)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('what colour is the sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 2.8536498134118726e-35)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much should i invest in The Bank of England')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formulating Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_query(qns):\n",
    "    qns_head = qns.split()[0]\n",
    "    ner_gpe = get_continuous_chunks(qns, \"GPE\")\n",
    "    ner_person = get_continuous_chunks(qns, \"PERSON\")\n",
    "    ner_org = get_continuous_chunks(qns, \"ORGANIZATION\")\n",
    "    ans_type = classify_qns(qns)\n",
    "    return [[qns_head], ner_gpe, ner_person, ner_org, ans_type]\n",
    "#     return {\"qns_head\":qns_head,\n",
    "#             \"ner_gpe\": ner_gpe,\n",
    "#             \"ner_person\": ner_person,\n",
    "#             \"ner_org\": ner_org,\n",
    "#             \"ans_type\": ans_type\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text, label):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "#     print(chunked)\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() == label:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "#             print('current_chunk', current_chunk)\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "#             print('named', named_entity)\n",
    "#             print('continuous', continuous_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qns_head': 'How',\n",
       " 'ner_gpe': ['New York'],\n",
       " 'ner_person': [],\n",
       " 'ner_org': [],\n",
       " 'ans_type': ('NUMERIC', 4.522772464857608e-36)}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = formulate_query('How much is the annual salary in New York city?')\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Answer Retrieval by Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(cleaned_sent_lower):\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(cleaned_sent_lower)\n",
    "    \n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names())\n",
    "    cosim = cosine_similarity(df, df)\n",
    "    return cosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3(cosim):\n",
    "    top3prob = np.sort(cosim[-1])[::-1][1:4]\n",
    "    top3docs = []\n",
    "    for prob in top3prob:\n",
    "        doc_num = np.where(cosim[-1] == prob)[0][0]\n",
    "#         print(\"Doc:\", doc_num, \", Cosine:\", prob)\n",
    "#         print(cleaned_sent_lower[doc_num])\n",
    "        top3docs.append(cleaned_sent_lower[doc_num])\n",
    "    return top3docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_1(query_ans_type, top3docs):\n",
    "    output = {0:0, 1:0, 2:0}\n",
    "    if query_ans_type[0] == 'NUMERIC':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            r1 = re.findall(r\"[0-9]+\",each)\n",
    "    #         print(r1)\n",
    "            if r1!=[]:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'LOCATION':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"GPE\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'HUMAN':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"PEOPLE\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_2(query_keywords, top3docs, output):\n",
    "    for each in query_keywords:\n",
    "        index = 0\n",
    "        for doc in top3docs:\n",
    "            if each in doc:\n",
    "                output[index] += 1\n",
    "            index += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_doc(top3docs, output):\n",
    "    max_value = max(output.values())  # maximum value\n",
    "    max_keys = [k for k, v in output.items() if v == max_value] # getting all keys containing the `maximum`\n",
    "    return top3docs[max_keys[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shorten answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate answer template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Check for Semantic answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a random financial article context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_qns(context, qns):\n",
    "    text = str(context.read())\n",
    "    sentences = text.split(\".\")\n",
    "\n",
    "    #qns analysis\n",
    "    query = formulate_query(qns)\n",
    "    query_keywords = query[1] + query[2] + query[3]\n",
    "    query_ans_type = query[4]\n",
    "    query_ans_type\n",
    "    \n",
    "    # Remove trailing \\n\n",
    "    cleaned_sent_lower = [sent.replace(\"\\n\", \"\") for sent in sentences]\n",
    "\n",
    "    #add test_doc\n",
    "    cleaned_sent_lower.append(qns)\n",
    "\n",
    "    #compute similarity\n",
    "    cosim = compute_similarity(cleaned_sent_lower)\n",
    "    \n",
    "    #gettop3 docs\n",
    "    top3docs = get_top3(cosim)\n",
    "\n",
    "    # get evaluated ans I\n",
    "    output = evaluate_ans_1(query_ans_type, top3docs)\n",
    "#     print(output)\n",
    "    \n",
    "     # get evaluated ans II\n",
    "    output = evaluate_ans_2(query_keywords, top3docs, output)\n",
    "#     print(output)\n",
    "    \n",
    "    #get ans\n",
    "    final_doc = get_final_doc(top3docs, output)\n",
    "    return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' An annual salary of $35,000 in New York City, for example, would leave you with around $27,490 after federal taxes without exemptions for the 2020-2021 filing seasonâ€”about $2,291 a month'"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "qns = 'How much is the annual salary in New York city?' #works when qns and ask are near to each other\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Disability income insurance protects your greatest assetâ€”the ability to earn an incomeâ€”by providing you with a steady income if you ever become unable to work for an extended period of time due to illness or injury'"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "qns = 'What is Disability income insurance?' #works when qns and ask are near to each other\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Fifthly, Start Saving for Retirement'"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "qns = 'Why should I start saving for retirement?' #limitations: pick up line that is most similar but not neccesarily the ans\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Read the policy carefully to see what's covered and what isn't\""
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "\n",
    "qns = 'What insurance will I get when I am employed?' #limitations: you're, I perspective\n",
    "ans_qns(context, qns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
