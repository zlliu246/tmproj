{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string, random\n",
    "\n",
    "#packages\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "# LDA Model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "\n",
    "#sklearn & gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Building Question Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>ABBREVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5447</td>\n",
       "      <td>What 's the shape of a camel 's spine ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5448</td>\n",
       "      <td>What type of currency is used in China ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5449</td>\n",
       "      <td>What is the temperature today ?</td>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>What is the temperature for cooking ?</td>\n",
       "      <td>NUMERIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5451</td>\n",
       "      <td>What currency is used in Australia ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5452 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions         class\n",
       "0     How did serfdom develop in and then leave Russ...   DESCRIPTION\n",
       "1      What films featured the character Popeye Doyle ?        ENTITY\n",
       "2     How can I find a list of celebrities ' real na...   DESCRIPTION\n",
       "3     What fowl grabs the spotlight after the Chines...        ENTITY\n",
       "4                       What is the full form of .com ?  ABBREVIATION\n",
       "...                                                 ...           ...\n",
       "5447            What 's the shape of a camel 's spine ?        ENTITY\n",
       "5448           What type of currency is used in China ?        ENTITY\n",
       "5449                    What is the temperature today ?       NUMERIC\n",
       "5450              What is the temperature for cooking ?       NUMERIC\n",
       "5451               What currency is used in Australia ?        ENTITY\n",
       "\n",
       "[5452 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"Question_Classification_Dataset.csv\")\n",
    "training_data = training_data[[\"Questions\", \"Category0\"]]\n",
    "training_data = training_data.rename(columns={\"Category0\": \"class\"})\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_tdm(df, specific_class):\n",
    "    D_docs = [row['Questions'] for index,row in training_data.iterrows() if row['class'] == specific_class]\n",
    "    vec_D = CountVectorizer()\n",
    "    X_D = vec_D.fit_transform(D_docs)\n",
    "    tdm_D = pd.DataFrame(X_D.toarray(), columns=vec_D.get_feature_names())\n",
    "\n",
    "    return tdm_D, vec_D, X_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_D, vec_D, X_D  = produce_tdm(training_data, \"DESCRIPTION\")\n",
    "tdm_E, vec_E, X_E = produce_tdm(training_data, \"ENTITY\")\n",
    "tdm_A, vec_A, X_A = produce_tdm(training_data, \"ABBREVIATION\")\n",
    "tdm_H, vec_H, X_H = produce_tdm(training_data, \"HUMAN\")\n",
    "tdm_N, vec_N, X_N = produce_tdm(training_data, \"NUMERIC\")\n",
    "tdm_L, vec_L, X_L = produce_tdm(training_data, \"LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_freq(vec, X):\n",
    "    word_list = vec.get_feature_names()\n",
    "    count_list = X.toarray().sum(axis=0) \n",
    "    freq = dict(zip(word_list,count_list))\n",
    "    freq\n",
    "\n",
    "    return freq, count_list, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_D, count_list_D, word_list_D = produce_freq(vec_D, X_D)\n",
    "freq_E, count_list_E, word_list_E = produce_freq(vec_E, X_E)\n",
    "freq_A, count_list_A, word_list_A = produce_freq(vec_A, X_A)\n",
    "freq_H, count_list_H, word_list_H = produce_freq(vec_H, X_H)\n",
    "freq_N, count_list_N, word_list_N = produce_freq(vec_N, X_N)\n",
    "freq_L, count_list_L, word_list_L = produce_freq(vec_L, X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(count_list, word_list):\n",
    "    prob = []\n",
    "    for count in count_list:\n",
    "        prob.append(count/len(word_list))\n",
    "    return dict(zip(word_list, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_D = get_prob(count_list_D, word_list_D)\n",
    "prob_E = get_prob(count_list_E, word_list_E)\n",
    "prob_A = get_prob(count_list_A, word_list_A)\n",
    "prob_H = get_prob(count_list_H, word_list_H)\n",
    "prob_N = get_prob(count_list_N, word_list_N)\n",
    "prob_L = get_prob(count_list_L, word_list_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [row['Questions'] for index,row in training_data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(docs)\n",
    "\n",
    "total_features = len(vec.get_feature_names())\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_D = count_list_D.sum(axis=0)\n",
    "total_cnts_features_E = count_list_E.sum(axis=0)\n",
    "total_cnts_features_A = count_list_A.sum(axis=0)\n",
    "total_cnts_features_H = count_list_H.sum(axis=0)\n",
    "total_cnts_features_N = count_list_N.sum(axis=0)\n",
    "total_cnts_features_L = count_list_L.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_with_qns(new_word_list, freq, total_cnts_features, total_features):\n",
    "    prob_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq.keys():\n",
    "            count = freq[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    output = dict(zip(new_word_list,prob_with_ls))\n",
    "    value_list = output.values()\n",
    "    value_list\n",
    "    \n",
    "    prob = 1\n",
    "    for each in value_list:\n",
    "        prob *= each\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_qns(qns):\n",
    "    new_word_list = word_tokenize(qns)\n",
    "    \n",
    "    prob_D = get_prob_with_qns(new_word_list, freq_D, total_cnts_features_D, total_features)\n",
    "    prob_E = get_prob_with_qns(new_word_list, freq_E, total_cnts_features_E, total_features)\n",
    "    prob_A = get_prob_with_qns(new_word_list, freq_A, total_cnts_features_A, total_features)\n",
    "    prob_H = get_prob_with_qns(new_word_list, freq_H, total_cnts_features_H, total_features)\n",
    "    prob_N = get_prob_with_qns(new_word_list, freq_N, total_cnts_features_N, total_features)\n",
    "    prob_L = get_prob_with_qns(new_word_list, freq_L, total_cnts_features_L, total_features)\n",
    "\n",
    "    prob = [prob_D, prob_E, prob_A, prob_H, prob_N, prob_L]\n",
    "    classes = [\"DESCRIPTION\", \"ENTITY\", \"ABBREVIATION\", 'HUMAN', \"NUMERIC\", \"LOCATION\"]\n",
    "    return(classes[prob.index(max(prob))], max(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 1.2506703038627668e-14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much is the book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOCATION', 2.135747124966801e-08)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('where is singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HUMAN', 1.777338870239113e-08)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('who is beyonce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DESCRIPTION', 1.7397241521486881e-13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('what colour is the sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 2.8536498134118726e-35)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much should i invest in The Bank of England')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 2.8536498134118726e-35)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much should i invest in The Bank of England')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formulating Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text, label):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "#     print(chunked)\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() == label:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "#             print('current_chunk', current_chunk)\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "#             print('named', named_entity)\n",
    "#             print('continuous', continuous_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_query(qns):\n",
    "    qns_head = qns.split()[0]\n",
    "    ner_gpe = get_continuous_chunks(qns, \"GPE\")\n",
    "    ner_person = get_continuous_chunks(qns, \"PERSON\")\n",
    "    ner_org = get_continuous_chunks(qns, \"ORGANIZATION\")\n",
    "    ans_type = classify_qns(qns)\n",
    "    return [[qns_head], ner_gpe, ner_person, ner_org, ans_type]\n",
    "#     return {\"qns_head\":qns_head,\n",
    "#             \"ner_gpe\": ner_gpe,\n",
    "#             \"ner_person\": ner_person,\n",
    "#             \"ner_org\": ner_org,\n",
    "#             \"ans_type\": ans_type\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How'], ['Singapore'], [], [], ('NUMERIC', 8.658558751366473e-39)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formulate_query('How much is the fine for violating lemon law in Singapore?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Answer Retrieval by Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(cleaned_sent_lower):\n",
    "#     count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    sparse_matrix = count_vectorizer.fit_transform(cleaned_sent_lower)\n",
    "    \n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names())\n",
    "    cosim = cosine_similarity(df, df)\n",
    "    return cosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3(cosim, cleaned_sent_lower):\n",
    "    threshold = 0.2 #edit this accordingly\n",
    "    top3prob = np.sort(cosim[-1])[::-1][1:4]\n",
    "    top3docs = []\n",
    "    for prob in top3prob:\n",
    "        if prob >= threshold:\n",
    "            doc_num = np.where(cosim[-1] == prob)[0][0]\n",
    "            print(\"Doc:\", doc_num, \", Cosine:\", prob)\n",
    "#             print(cleaned_sent_lower[doc_num])\n",
    "            top3docs.append(cleaned_sent_lower[doc_num])\n",
    "    if top3docs == []:\n",
    "        top3docs.append(\"\")\n",
    "    return top3docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_1(query_ans_type, top3docs):\n",
    "    output = {0:0, 1:0, 2:0}\n",
    "    if query_ans_type[0] == 'NUMERIC':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            r1 = re.findall(r\"[0-9,]+\",each) \n",
    "            if r1!=[]:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'LOCATION':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"GPE\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'HUMAN':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"PERSON\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_2(query_keywords, top3docs, output):\n",
    "    for each in query_keywords:\n",
    "        index = 0\n",
    "#         print('keywords', query_keywords)\n",
    "#         print(top3docs)\n",
    "        for doc in top3docs:\n",
    "            if each in doc:\n",
    "                output[index] += 1\n",
    "            index += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_doc(top3docs, output):\n",
    "    max_value = max(output.values())  # maximum value\n",
    "    max_keys = [k for k, v in output.items() if v == max_value] # getting all keys containing the `maximum`\n",
    "    return top3docs[max_keys[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate answer template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query_ans_type, qns_head, final_doc):\n",
    "    #answer full sentence for WHAT, WHY\n",
    "    sent_tokens = word_tokenize(final_doc)\n",
    "    tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "    if final_doc == \"\":\n",
    "        return \"Sorry, I do not have the answer to this question.\"    \n",
    "    elif qns_head[0] == \"Who\": # Expect name (NNP), of(IN), position(NNP), organization (NNP)\n",
    "        temp = []\n",
    "        output = []\n",
    "        cont = False\n",
    "        for x,y in tagged_sent:\n",
    "            if \"NNP\" in y and cont == False:\n",
    "                temp.append(x)\n",
    "                cont = True\n",
    "            elif \"NNP\" in y and cont == True:\n",
    "                output.append(x)\n",
    "                temp = []\n",
    "            elif y==\"IN\" and cont == True:\n",
    "                output.append(x)\n",
    "                temp = []\n",
    "        output = \" \".join(output)\n",
    "        return \"The person is \" + output #bigram doesnt work\n",
    "    \n",
    "    elif qns_head[0] == \"Where\": # Expect located (VBN) at location (NN)\n",
    "        output = get_continuous_chunks(final_doc, \"GPE\")\n",
    "        return \"At \" + output[0]\n",
    "            \n",
    "    elif qns_head[0] == \"When\":\n",
    "        for x,y in tagged_sent:\n",
    "            if \"CD\" in y:\n",
    "                return x\n",
    "            \n",
    "    elif query_ans_type == \"NUMERIC\":\n",
    "        output = re.findall(r\"[$%0-9]+\", final_doc) #accept numeric, percentage, price\n",
    "        return \"It is \" + output[0]\n",
    "    \n",
    "    return final_doc #answer full sentence for WHAT, WHY, HOW as these questions may have a wide variety of paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA testing revealed the body of Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\n"
     ]
    }
   ],
   "source": [
    "final_doc = \"DNA testing revealed the body of Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\"\n",
    "qns_head = \"Where\" \n",
    "query_ans_type = \"LOCATION\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA testing revealed the body of Swiss National Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\n"
     ]
    }
   ],
   "source": [
    "final_doc = \"DNA testing revealed the body of Swiss National Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\"\n",
    "qns_head = \"Where\" \n",
    "query_ans_type = \"LOCATION\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is $3000\n"
     ]
    }
   ],
   "source": [
    "# Testing numeric qns\n",
    "final_doc = \"The fine for lemon law is $3000.\"\n",
    "qns_head = \"How\" #how much is the fine?\n",
    "query_ans_type = \"NUMERIC\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama, President of the United States, has addresses the global financial crisis.\n"
     ]
    }
   ],
   "source": [
    "# Testing who qns #1\n",
    "final_doc = \"Barack Obama, President of the United States, has addresses the global financial crisis.\"\n",
    "qns_head = \"Who\" #how much is the fine?\n",
    "query_ans_type = \"HUMAN\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As President of United States, Barack Obama addressed the global financial crisis.\n"
     ]
    }
   ],
   "source": [
    "# Testing who qns #2. Limitation: sensitive to paraphasing!\n",
    "final_doc = \"As President of United States, Barack Obama addressed the global financial crisis.\"\n",
    "qns_head = \"Who\" #how much is the fine?\n",
    "query_ans_type = \"HUMAN\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is 2\n"
     ]
    }
   ],
   "source": [
    "# Testing when qns\n",
    "final_doc = \"The robbery occured at 2am.\"\n",
    "qns_head = \"When\" #when did the robbery happen?\n",
    "query_ans_type = \"NUMERIC\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a random financial article context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_qns(context, qns):\n",
    "#     context = str(context.read())\n",
    "    sentences = context.split(\".\")\n",
    "\n",
    "    #qns analysis\n",
    "    query = formulate_query(qns)\n",
    "    qns_head = query[0]\n",
    "    query_keywords = query[1] + query[2] + query[3]\n",
    "    query_ans_type = query[4]\n",
    "#     print(query_ans_type)\n",
    "    \n",
    "    # Remove trailing \\n\n",
    "    cleaned_sent_lower = [sent.replace(\"\\n\", \"\") for sent in sentences]\n",
    "#     print(\"cleaned\", cleaned_sent_lower)\n",
    "\n",
    "    #add test_doc\n",
    "    cleaned_sent_lower.append(qns)\n",
    "\n",
    "    #compute similarity\n",
    "    cosim = compute_similarity(cleaned_sent_lower)\n",
    "    \n",
    "    #gettop3 docs\n",
    "    top3docs = get_top3(cosim, cleaned_sent_lower)\n",
    "#     print(top3docs)\n",
    "\n",
    "    # get evaluated ans I\n",
    "    output = evaluate_ans_1(query_ans_type, top3docs)\n",
    "#     print(output)\n",
    "    \n",
    "     # get evaluated ans II\n",
    "    output = evaluate_ans_2(query_keywords, top3docs, output)\n",
    "#     print(output)\n",
    "    \n",
    "    #get ans\n",
    "    final_doc = get_final_doc(top3docs, output)\n",
    "    \n",
    "    #answer template\n",
    "    return generate_answer(query_ans_type, qns_head, final_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "qns = 'What is Disability income insurance?' #works when qns and ask are near to each other\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "qns = 'Why should I start saving for retirement?' #limitations: pick up line that is most similar but not neccesarily the ans\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitations - synonyms \n",
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "\n",
    "qns = 'What insurance will I get when I am employed?'\n",
    "print(ans_qns(context, qns))\n",
    "\n",
    "# qns = 'What insurance will I get when I am hired?'\n",
    "# print(ans_qns(context, qns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Evaluation.csv\")\n",
    "df = df[[\"Context\", \"Question\"]]\n",
    "context_lst = df['Context'].values.tolist()\n",
    "qns_lst = df['Question'].values.tolist()\n",
    "# context_lst\n",
    "# qns_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qns: What do we call the willingly-assumed burdens placed upon parties to both treaties and contracts?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 2 , Cosine: 0.45328160783192867\n",
      "qns: In United States, which state has the highest rate of death sentences per person?\n",
      "ans  Among them, Alabama has the highest per capita rate of death sentences \n",
      "\n",
      "Doc: 2 , Cosine: 0.5013999312475736\n",
      "qns: What is the penalty for unlawful performances that are willful and for profit?\n",
      "ans  copyright law was added in 1897, which established a misdemeanor penalty for \"unlawful performances and representations of copyrighted dramatic and musical compositions\" if the violation had been \"willful and for profit \n",
      "\n",
      "Doc: 4 , Cosine: 0.4232304151234757\n",
      "Doc: 6 , Cosine: 0.20861519820541247\n",
      "qns: What type of law handles patent infringement cases in China?\n",
      "ans , in the United States) but several jurisdictions incorporate infringement in criminal law also (for example, Argentina, China, France, Japan, Russia, South Korea) \n",
      "\n",
      "Doc: 4 , Cosine: 0.4232304151234757\n",
      "Doc: 6 , Cosine: 0.20861519820541247\n",
      "qns: In Russia, what type of law handles patent infringement cases?\n",
      "ans , in the United States) but several jurisdictions incorporate infringement in criminal law also (for example, Argentina, China, France, Japan, Russia, South Korea) \n",
      "\n",
      "qns: Who appoints a judge?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 1 , Cosine: 0.27879501552021146\n",
      "qns: Who can issue a pardon?\n",
      "ans The person is  \n",
      "\n",
      "Doc: 4 , Cosine: 0.45861841578412416\n",
      "Doc: 0 , Cosine: 0.20596706040263332\n",
      "qns: What type of law handles patent infringement cases in the US?\n",
      "ans  In general, patent infringement cases are handled under civil law (e \n",
      "\n",
      "Doc: 1 , Cosine: 0.2200135932403467\n",
      "qns: Who has the authority to issue a reprieve?\n",
      "ans The person is  \n",
      "\n",
      "Doc: 0 , Cosine: 0.5491347594968131\n",
      "qns: Who is the commander and chief of the Army?\n",
      "ans The person is in Chief of Army Navy of United States \n",
      "\n",
      "Doc: 1 , Cosine: 0.28019299928299196\n",
      "qns: The constitution set boundaries for case law that originates from where?\n",
      "ans  The Constitution sets out the boundaries of federal law, which consists of acts of Congress, treaties ratified by the Senate, regulations promulgated by the executive branch, and case law originating from the federal judiciary \n",
      "\n",
      "Doc: 1 , Cosine: 0.30074385302353734\n",
      "qns: What sets out the boundries of federal law?\n",
      "ans  The Constitution sets out the boundaries of federal law, which consists of acts of Congress, treaties ratified by the Senate, regulations promulgated by the executive branch, and case law originating from the federal judiciary \n",
      "\n",
      "Doc: 8 , Cosine: 0.39347321056645657\n",
      "qns: What is considered day-to-day, operational law?\n",
      "ans  law (especially the actual \"living law\" of contract, tort, property, criminal, and family law experienced by the majority of citizens on a day-to-day basis) consists primarily of state law, which can and does vary greatly from one state to the next \n",
      "\n",
      "Doc: 0 , Cosine: 0.602322381140847\n",
      "qns: Which law covers the wrongs that humans inflict upon each other?\n",
      "ans Tort law covers the entire imaginable spectrum of wrongs which humans can inflict upon each other, and of course, partially overlaps with wrongs also punishable by criminal law \n",
      "\n",
      "Doc: 0 , Cosine: 0.46628706213627197\n",
      "qns: Who signs a bill into a law?\n",
      "ans The person is into Congress over Office of Federal Register OFR of National Archives Records Administration NARA for as \n",
      "\n",
      "Doc: 3 , Cosine: 0.21898250055185361\n",
      "qns: What happens to the rule of law if a government does not have an effective system for maintenance and restoration?\n",
      "ans  Government based upon the rule of law is called nomocracy \n",
      "\n",
      "qns: According to Plato, who was above the law?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "qns: To what did Plato compare a government that follows laws?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 0 , Cosine: 0.29380162193685067\n",
      "Doc: 2 , Cosine: 0.26083451415475023\n",
      "qns: What counters the rule of law?\n",
      "ans The functional interpretation of the term \"rule of law\", consist`ent with the traditional English meaning, contrasts the \"rule of law\" with the \"rule of man \n",
      "\n",
      "Doc: 1 , Cosine: 0.4058848876951201\n",
      "Doc: 2 , Cosine: 0.21011748094483168\n",
      "Doc: 2 , Cosine: 0.21011748094483168\n",
      "qns: Is it possible for a bilateral treaty to have more than two parties?\n",
      "ans  It is possible, however, for a bilateral treaty to have more than two parties; consider for instance the bilateral treaties between Switzerland and the European Union (EU) following the Swiss rejection of the European Economic Area agreement \n",
      "\n",
      "Doc: 2 , Cosine: 0.542298789469279\n",
      "qns: Broad terms in the laws allow for what?\n",
      "ans  The laws are often framed in broad terms, which allow flexibility in their application depending on the nature of the game \n",
      "\n",
      "Doc: 5 , Cosine: 0.41442191784103904\n",
      "qns: What did the court rule outlawing polygamy was?\n",
      "ans \" Considering this, the court ruled that outlawing polygamy was constitutional \n",
      "\n",
      "Doc: 1 , Cosine: 0.27029520471995755\n",
      "qns: Traditionally, what must a state do in order for an obligation to arise in international law?\n",
      "ans  As obligations in international law are traditionally viewed as arising only from the consent of states, many treaties expressly allow a state to withdraw as long as it follows certain procedures of notification \n",
      "\n",
      "qns: Who can limit judicial review of a law?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 0 , Cosine: 0.3274472246381235\n",
      "Doc: 8 , Cosine: 0.24221681727072106\n",
      "qns: Federal law overrides what laws?\n",
      "ans Federal law and treaties, so long as they are in accordance with the Constitution, preempt conflicting state and territorial laws in the 50 U \n",
      "\n",
      "Doc: 0 , Cosine: 0.331827381585366\n",
      "qns: What is a key qualifier for determining good governance?\n",
      "ans The rule of law has been considered as one of the key dimensions that determine the quality and good governance of a country \n",
      "\n",
      "Doc: 0 , Cosine: 0.25695357961449533\n",
      "qns: Who is the head of each government department?\n",
      "ans The person is  \n",
      "\n",
      "Doc: 2 , Cosine: 0.3992290788122406\n",
      "Doc: 1 , Cosine: 0.28285100328908597\n",
      "qns: Who do the Provincial Ministers report to?\n",
      "ans The person is by Minister Politician Provincial Secretary A of BPS-20 BPS-21 \n",
      "\n",
      "Doc: 1 , Cosine: 0.2980307953471086\n",
      "Doc: 3 , Cosine: 0.29026251451881546\n",
      "Doc: 5 , Cosine: 0.23478796091255194\n",
      "qns: Who do the Provincial Secretaries report to?\n",
      "ans The person is by Minister Politician Provincial Secretary A of BPS-20 BPS-21 \n",
      "\n",
      "Doc: 4 , Cosine: 0.36565589513486246\n",
      "Doc: 2 , Cosine: 0.23781075295572476\n",
      "qns: What rank is the Chief Secretary?\n",
      "ans  All Ministers report to the Chief Minister, who is the Chief Executive \n",
      "\n",
      "Doc: 2 , Cosine: 0.3304755456139216\n",
      "Doc: 1 , Cosine: 0.2119249320488323\n",
      "qns: Who elects the Chief Minister?\n",
      "ans The person is Minister Shahbaz Sharif Chief Minister of Punjab as after Governor from February March \n",
      "\n",
      "Doc: 1 , Cosine: 0.37333536849284255\n",
      "qns: Why do some police acts limit when police can interfere without court orders?\n",
      "ans  To ensure that the police would not interfere in the regular competencies of the courts of law, some police acts require that the police may only interfere in such cases where protection from courts cannot be obtained in time, and where, without interference of the police, the realization of the private right would be impeded \n",
      "\n",
      "Doc: 1 , Cosine: 0.3886764473724845\n",
      "qns: What could be impeded without police interference?\n",
      "ans  To ensure that the police would not interfere in the regular competencies of the courts of law, some police acts require that the police may only interfere in such cases where protection from courts cannot be obtained in time, and where, without interference of the police, the realization of the private right would be impeded \n",
      "\n",
      "Doc: 2 , Cosine: 0.4236670702563536\n",
      "qns: How could police help the owner when a restaurant guest doesn't pay because their wallet got stolen?\n",
      "ans  This would, for example, allow police to establish a restaurant guest's identity and forward it to the innkeeper in a case where the guest cannot pay the bill at nighttime because his wallet had just been stolen from the restaurant table \n",
      "\n",
      "qns: What can only Inspector-ranked UK officers do?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "qns: What can only Superintendent-ranked UK officers do?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "qns: What powers of a new UK police officer are the same as a Commissioner's?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 2 , Cosine: 0.2276356507468253\n",
      "qns: Which amendment contains the Equal Protection Clause?\n",
      "ans  In 1989 the Supreme Court of the United States declared the Board of Estimate unconstitutional on the grounds that Brooklyn, the most populous borough, had no greater effective representation on the Board than Staten Island, the least populous borough, a violation of the Fourteenth Amendment's Equal Protection Clause pursuant to the high court's 1964 \"one man, one vote\" decision \n",
      "\n",
      "qns: What did the decision ultimately uphold?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 0 , Cosine: 0.3430836515876974\n",
      "qns: What distinction is undoubtedly permissible?\n",
      "ans Nevertheless, although a distinction between lawful and unlawful hunting is undoubtedly permissible, it is certain that a bishop can absolutely prohibit all hunting to the clerics of his diocese, as was done by synods at Milan, Avignon, LiÃƒÂ¨ge, Cologne, and elsewhere \n",
      "\n",
      "qns: How long are presidential terms?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 0 , Cosine: 0.3143646540700923\n",
      "qns: What was the outcome of Tulisa's trial?\n",
      "ans At her subsequent trial, the case against Tulisa collapsed at Southwark Crown Court in July 2014, with the judge commenting that there were \"strong grounds\" to believe that Mahmood had lied at a pre-trial hearing and tried to manipulate evidence against the co-defendant Tulisa \n",
      "\n",
      "Doc: 2 , Cosine: 0.23190177077808324\n",
      "qns: Who is Ruth Dreifuss?\n",
      "ans The person is Council Elisabeth Kopp from Ruth Dreifuss in \n",
      "\n",
      "qns: Why did Burke go against the protestors?\n",
      "ans Sorry, I do not have the answer to this question. \n",
      "\n",
      "Doc: 0 , Cosine: 0.33703039144354924\n",
      "qns: When was the case against Tulisa collapsed?\n",
      "ans 2014 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for x in range(len(context_lst)):\n",
    "    context = context_lst[x]\n",
    "    qns = qns_lst[x]\n",
    "    a = ans_qns(context, qns)\n",
    "    print('qns:', qns)\n",
    "    print(\"ans\",a,  \"\\n\")\n",
    "    output.append(a)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(output,columns=['answer'])\n",
    "result_df.to_csv('evaluation_result_v4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
