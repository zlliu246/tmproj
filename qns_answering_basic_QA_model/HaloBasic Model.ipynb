{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string, random\n",
    "\n",
    "#packages\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "# LDA Model\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "\n",
    "#sklearn & gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Building Question Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Question_Classification_Dataset.csv\")\n",
    "df = df[[\"Questions\", \"Category0\"]]\n",
    "df = df.rename(columns={\"Category0\": \"class\"})\n",
    "df\n",
    "training_data, test_data = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_tdm(df, specific_class):\n",
    "    D_docs = [row['Questions'] for index,row in training_data.iterrows() if row['class'] == specific_class]\n",
    "    vec_D = CountVectorizer()\n",
    "    X_D = vec_D.fit_transform(D_docs)\n",
    "    tdm_D = pd.DataFrame(X_D.toarray(), columns=vec_D.get_feature_names())\n",
    "\n",
    "    return tdm_D, vec_D, X_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_D, vec_D, X_D  = produce_tdm(training_data, \"DESCRIPTION\")\n",
    "tdm_E, vec_E, X_E = produce_tdm(training_data, \"ENTITY\")\n",
    "tdm_A, vec_A, X_A = produce_tdm(training_data, \"ABBREVIATION\")\n",
    "tdm_H, vec_H, X_H = produce_tdm(training_data, \"HUMAN\")\n",
    "tdm_N, vec_N, X_N = produce_tdm(training_data, \"NUMERIC\")\n",
    "tdm_L, vec_L, X_L = produce_tdm(training_data, \"LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_freq(vec, X):\n",
    "    word_list = vec.get_feature_names()\n",
    "    count_list = X.toarray().sum(axis=0) \n",
    "    freq = dict(zip(word_list,count_list))\n",
    "    freq\n",
    "\n",
    "    return freq, count_list, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_D, count_list_D, word_list_D = produce_freq(vec_D, X_D)\n",
    "freq_E, count_list_E, word_list_E = produce_freq(vec_E, X_E)\n",
    "freq_A, count_list_A, word_list_A = produce_freq(vec_A, X_A)\n",
    "freq_H, count_list_H, word_list_H = produce_freq(vec_H, X_H)\n",
    "freq_N, count_list_N, word_list_N = produce_freq(vec_N, X_N)\n",
    "freq_L, count_list_L, word_list_L = produce_freq(vec_L, X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(count_list, word_list):\n",
    "    prob = []\n",
    "    for count in count_list:\n",
    "        prob.append(count/len(word_list))\n",
    "    return dict(zip(word_list, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_D = get_prob(count_list_D, word_list_D)\n",
    "prob_E = get_prob(count_list_E, word_list_E)\n",
    "prob_A = get_prob(count_list_A, word_list_A)\n",
    "prob_H = get_prob(count_list_H, word_list_H)\n",
    "prob_N = get_prob(count_list_N, word_list_N)\n",
    "prob_L = get_prob(count_list_L, word_list_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7380"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [row['Questions'] for index,row in training_data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(docs)\n",
    "\n",
    "total_features = len(vec.get_feature_names())\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnts_features_D = count_list_D.sum(axis=0)\n",
    "total_cnts_features_E = count_list_E.sum(axis=0)\n",
    "total_cnts_features_A = count_list_A.sum(axis=0)\n",
    "total_cnts_features_H = count_list_H.sum(axis=0)\n",
    "total_cnts_features_N = count_list_N.sum(axis=0)\n",
    "total_cnts_features_L = count_list_L.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_with_qns(new_word_list, freq, total_cnts_features, total_features):\n",
    "    prob_with_ls = []\n",
    "    for word in new_word_list:\n",
    "        if word in freq.keys():\n",
    "            count = freq[word]\n",
    "        else:\n",
    "            count = 0\n",
    "        prob_with_ls.append((count + 1)/(total_cnts_features + total_features))\n",
    "    output = dict(zip(new_word_list,prob_with_ls))\n",
    "    value_list = output.values()\n",
    "    value_list\n",
    "    \n",
    "    prob = 1\n",
    "    for each in value_list:\n",
    "        prob *= each\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_qns(qns):\n",
    "    new_word_list = word_tokenize(qns)\n",
    "    \n",
    "    prob_D = get_prob_with_qns(new_word_list, freq_D, total_cnts_features_D, total_features)\n",
    "    prob_E = get_prob_with_qns(new_word_list, freq_E, total_cnts_features_E, total_features)\n",
    "    prob_A = get_prob_with_qns(new_word_list, freq_A, total_cnts_features_A, total_features)\n",
    "    prob_H = get_prob_with_qns(new_word_list, freq_H, total_cnts_features_H, total_features)\n",
    "    prob_N = get_prob_with_qns(new_word_list, freq_N, total_cnts_features_N, total_features)\n",
    "    prob_L = get_prob_with_qns(new_word_list, freq_L, total_cnts_features_L, total_features)\n",
    "\n",
    "    prob = [prob_D, prob_E, prob_A, prob_H, prob_N, prob_L]\n",
    "    classes = [\"DESCRIPTION\", \"ENTITY\", \"ABBREVIATION\", 'HUMAN', \"NUMERIC\", \"LOCATION\"]\n",
    "    return(classes[prob.index(max(prob))], max(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2486</td>\n",
       "      <td>Where was `` I have fallen , and I can 't get ...</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1794</td>\n",
       "      <td>What is the best way to overcome a fear ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4422</td>\n",
       "      <td>Why shouldn 't you remove a bee stinger with t...</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4829</td>\n",
       "      <td>What was the killer whale who died at Sea Worl...</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4323</td>\n",
       "      <td>What is InterLata Internet service ?</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>What types of water pollution are there ?</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>Where do chihuahuas come from ?</td>\n",
       "      <td>DESCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>What therapy attempts to elicit the `` primal ...</td>\n",
       "      <td>ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2752</td>\n",
       "      <td>Where are the headquarters of Eli Lilly ?</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1678</td>\n",
       "      <td>What are the largest libraries in the US ?</td>\n",
       "      <td>LOCATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1091 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions        class\n",
       "2486  Where was `` I have fallen , and I can 't get ...     LOCATION\n",
       "1794          What is the best way to overcome a fear ?       ENTITY\n",
       "4422  Why shouldn 't you remove a bee stinger with t...  DESCRIPTION\n",
       "4829  What was the killer whale who died at Sea Worl...       ENTITY\n",
       "4323               What is InterLata Internet service ?  DESCRIPTION\n",
       "...                                                 ...          ...\n",
       "965           What types of water pollution are there ?       ENTITY\n",
       "110                     Where do chihuahuas come from ?  DESCRIPTION\n",
       "190   What therapy attempts to elicit the `` primal ...       ENTITY\n",
       "2752          Where are the headquarters of Eli Lilly ?     LOCATION\n",
       "1678         What are the largest libraries in the US ?     LOCATION\n",
       "\n",
       "[1091 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB is 60.31164069660861 %\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = test_data['class'].ravel()\n",
    "predicted = []\n",
    "y_qns = test_data.Questions.values.tolist()\n",
    "for each in y_qns:\n",
    "    pred = classify_qns(each)\n",
    "    predicted.append(pred[0])\n",
    "y_pred = np.array(predicted)\n",
    "    \n",
    "\n",
    "print('Accuracy of NB is', accuracy_score(y_true, y_pred)*100,'%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 1.3949422481990203e-14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much is the book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LOCATION', 2.2940436429633338e-08)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('where is singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HUMAN', 2.052766480440759e-08)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('who is beyonce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DESCRIPTION', 2.1110269629894653e-13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('what colour is the sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 5.732248666737425e-35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much should i invest in The Bank of England')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NUMERIC', 5.732248666737425e-35)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_qns('How much should i invest in The Bank of England')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Formulating Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text, label):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "#     print(chunked)\n",
    "    prev = None\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree and subtree.label() == label:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "#             print('current_chunk', current_chunk)\n",
    "        if current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "#             print('named', named_entity)\n",
    "#             print('continuous', continuous_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formulate_query(qns):\n",
    "    qns_head = qns.split()[0]\n",
    "    ner_gpe = get_continuous_chunks(qns, \"GPE\")\n",
    "    ner_person = get_continuous_chunks(qns, \"PERSON\")\n",
    "    ner_org = get_continuous_chunks(qns, \"ORGANIZATION\")\n",
    "    ans_type = classify_qns(qns)\n",
    "    return [[qns_head], ner_gpe, ner_person, ner_org, ans_type]\n",
    "#     return {\"qns_head\":qns_head,\n",
    "#             \"ner_gpe\": ner_gpe,\n",
    "#             \"ner_person\": ner_person,\n",
    "#             \"ner_org\": ner_org,\n",
    "#             \"ans_type\": ans_type\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How'], ['Singapore'], [], [], ('NUMERIC', 2.2332198045735305e-38)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formulate_query('How much is the fine for violating lemon law in Singapore?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Answer Retrieval by Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(cleaned_sent_lower):\n",
    "#     count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    sparse_matrix = count_vectorizer.fit_transform(cleaned_sent_lower)\n",
    "    \n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names())\n",
    "    cosim = cosine_similarity(df, df)\n",
    "    return cosim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top3(cosim, cleaned_sent_lower):\n",
    "    threshold = 0.2 #edit this accordingly\n",
    "    top3prob = np.sort(cosim[-1])[::-1][1:4]\n",
    "    top3docs = []\n",
    "    for prob in top3prob:\n",
    "        if prob >= threshold:\n",
    "            doc_num = np.where(cosim[-1] == prob)[0][0]\n",
    "#             print(\"Doc:\", doc_num, \", Cosine:\", prob)\n",
    "#             print(cleaned_sent_lower[doc_num])\n",
    "            top3docs.append(cleaned_sent_lower[doc_num])\n",
    "    if top3docs == []:\n",
    "        top3docs.append(\"\")\n",
    "    return top3docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_1(query_ans_type, top3docs):\n",
    "    output = {0:0, 1:0, 2:0}\n",
    "    if query_ans_type[0] == 'NUMERIC':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            r1 = re.findall(r\"[0-9,]+\",each) \n",
    "            if r1!=[]:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'LOCATION':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"GPE\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "\n",
    "    elif query_ans_type[0] == 'HUMAN':\n",
    "        index = 0\n",
    "        for each in top3docs:\n",
    "            if get_continuous_chunks(each, \"PERSON\") != []:\n",
    "                output[index] = 1\n",
    "            index +=1\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ans_2(query_keywords, top3docs, output):\n",
    "    for each in query_keywords:\n",
    "        index = 0\n",
    "#         print('keywords', query_keywords)\n",
    "#         print(top3docs)\n",
    "        for doc in top3docs:\n",
    "            if each in doc:\n",
    "                output[index] += 1\n",
    "            index += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_doc(top3docs, output):\n",
    "    max_value = max(output.values())  # maximum value\n",
    "    max_keys = [k for k, v in output.items() if v == max_value] # getting all keys containing the `maximum`\n",
    "    return top3docs[max_keys[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate answer template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query_ans_type, qns_head, final_doc):\n",
    "    #answer full sentence for WHAT, WHY\n",
    "    sent_tokens = word_tokenize(final_doc)\n",
    "    tagged_sent = nltk.pos_tag(sent_tokens)\n",
    "    if final_doc == \"\":\n",
    "        return \"Sorry, I do not have the answer to this question.\"    \n",
    "    elif qns_head[0] == \"Who\": # Expect name (NNP), of(IN), position(NNP), organization (NNP)\n",
    "        temp = []\n",
    "        output = []\n",
    "        cont = False\n",
    "        for x,y in tagged_sent:\n",
    "            if \"NNP\" in y and cont == False:\n",
    "                temp.append(x)\n",
    "                cont = True\n",
    "            elif \"NNP\" in y and cont == True:\n",
    "                output.append(x)\n",
    "                temp = []\n",
    "            elif y==\"IN\" and cont == True:\n",
    "                output.append(x)\n",
    "                temp = []\n",
    "        output = \" \".join(output)\n",
    "        return \"The person is \" + output #bigram doesnt work\n",
    "    \n",
    "    elif qns_head[0] == \"Where\": # Expect located (VBN) at location (NN)\n",
    "        output = get_continuous_chunks(final_doc, \"GPE\")\n",
    "        return \"At \" + output[0]\n",
    "            \n",
    "    elif qns_head[0] == \"When\":\n",
    "        for x,y in tagged_sent:\n",
    "            if \"CD\" in y:\n",
    "                return x\n",
    "            \n",
    "    elif query_ans_type == \"NUMERIC\":\n",
    "        output = re.findall(r\"[$%0-9]+\", final_doc) #accept numeric, percentage, price\n",
    "        return \"It is \" + output[0]\n",
    "    \n",
    "    return final_doc #answer full sentence for WHAT, WHY, HOW as these questions may have a wide variety of paraphrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA testing revealed the body of Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\n"
     ]
    }
   ],
   "source": [
    "final_doc = \"DNA testing revealed the body of Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\"\n",
    "qns_head = \"Where\" \n",
    "query_ans_type = \"LOCATION\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA testing revealed the body of Swiss National Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\n"
     ]
    }
   ],
   "source": [
    "final_doc = \"DNA testing revealed the body of Swiss National Beatrice Stoeckli, who was kidnapped in Timbuktu, Mali.\"\n",
    "qns_head = \"Where\" \n",
    "query_ans_type = \"LOCATION\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is $3000\n"
     ]
    }
   ],
   "source": [
    "# Testing numeric qns\n",
    "final_doc = \"The fine for lemon law is $3000.\"\n",
    "qns_head = \"How\" #how much is the fine?\n",
    "query_ans_type = \"NUMERIC\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama, President of the United States, has addresses the global financial crisis.\n"
     ]
    }
   ],
   "source": [
    "# Testing who qns #1\n",
    "final_doc = \"Barack Obama, President of the United States, has addresses the global financial crisis.\"\n",
    "qns_head = \"Who\" #how much is the fine?\n",
    "query_ans_type = \"HUMAN\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As President of United States, Barack Obama addressed the global financial crisis.\n"
     ]
    }
   ],
   "source": [
    "# Testing who qns #2. Limitation: sensitive to paraphasing!\n",
    "final_doc = \"As President of United States, Barack Obama addressed the global financial crisis.\"\n",
    "qns_head = \"Who\" #how much is the fine?\n",
    "query_ans_type = \"HUMAN\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is 2\n"
     ]
    }
   ],
   "source": [
    "# Testing when qns\n",
    "final_doc = \"The robbery occured at 2am.\"\n",
    "qns_head = \"When\" #when did the robbery happen?\n",
    "query_ans_type = \"NUMERIC\"\n",
    "print(generate_answer(query_ans_type, qns_head, final_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a random financial article context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ans_qns(context, qns):\n",
    "    sentences = context.split(\".\")\n",
    "\n",
    "    #qns analysis\n",
    "    query = formulate_query(qns)\n",
    "    qns_head = query[0]\n",
    "    query_keywords = query[1] + query[2] + query[3]\n",
    "    query_ans_type = query[4]\n",
    "#     print(query_ans_type)\n",
    "    \n",
    "    # Remove trailing \\n\n",
    "    cleaned_sent_lower = [sent.replace(\"\\n\", \"\") for sent in sentences]\n",
    "#     print(\"cleaned\", cleaned_sent_lower)\n",
    "\n",
    "    #add test_doc\n",
    "    cleaned_sent_lower.append(qns)\n",
    "\n",
    "    #compute similarity\n",
    "    cosim = compute_similarity(cleaned_sent_lower)\n",
    "    \n",
    "    #gettop3 docs\n",
    "    top3docs = get_top3(cosim, cleaned_sent_lower)\n",
    "#     print(top3docs)\n",
    "\n",
    "    # get evaluated ans I\n",
    "    output = evaluate_ans_1(query_ans_type, top3docs)\n",
    "#     print(output)\n",
    "    \n",
    "     # get evaluated ans II\n",
    "    output = evaluate_ans_2(query_keywords, top3docs, output)\n",
    "#     print(output)\n",
    "    \n",
    "    #get ans\n",
    "    final_doc = get_final_doc(top3docs, output)\n",
    "    \n",
    "    #answer template\n",
    "    return generate_answer(query_ans_type, qns_head, final_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An annual salary of $35,000 in New York City, for example, would leave you with around $27,490 after federal taxes without exemptions for the 2020-2021 filing season—about $2,291 a month\n"
     ]
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "context = str(context.read())\n",
    "qns = 'How much is the annual salary in New York city?' #works when qns and ask are near to each other\n",
    "print(ans_qns(context, qns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Disability income insurance protects your greatest asset—the ability to earn an income—by providing you with a steady income if you ever become unable to work for an extended period of time due to illness or injury'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "context = str(context.read())\n",
    "qns = 'What is Disability income insurance?' #works when qns and ask are near to each other\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Fifthly, Start Saving for Retirement'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "context = str(context.read())\n",
    "qns = 'Why should I start saving for retirement?' #limitations: pick up line that is most similar but not neccesarily the ans\n",
    "ans_qns(context, qns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If you're employed, your employer may offer health insurance, including high-deductible health plans that save on premiums and qualify you for a Health Savings Account (HSA)\n"
     ]
    }
   ],
   "source": [
    "#limitations - synonyms \n",
    "context = open(\"context.txt\", encoding=\"utf8\")\n",
    "context = str(context.read())\n",
    "qns = 'What insurance will I get when I am employed?'\n",
    "print(ans_qns(context, qns))\n",
    "\n",
    "# qns = 'What insurance will I get when I am hired?'\n",
    "# print(ans_qns(context, qns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Evaluation.csv\")\n",
    "df = df[[\"Context\", \"Question\", \"Answer\"]]\n",
    "context_lst = df['Context'].values.tolist()\n",
    "qns_lst = df['Question'].values.tolist()\n",
    "ans_lst = df['Answer'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for x in range(len(context_lst)):\n",
    "#     print(context_lst)\n",
    "    context = context_lst[x]\n",
    "    qns = qns_lst[x]\n",
    "    a = ans_qns(context, qns)\n",
    "    output.append(a)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(output,columns=['answer'])\n",
    "result_df.to_csv('evaluation_result_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
