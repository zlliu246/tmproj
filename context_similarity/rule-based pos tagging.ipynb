{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gigi/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "/Users/gigi/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from pprint import pprint\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "import warnings\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from sent2vec.vectorizer import Vectorizer as S2vectorizer\n",
    "tqdm_notebook.pandas()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import pipelines\n",
    "from transformers import pipeline\n",
    "nlp2 = pipeline(\"question-answering\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_columns', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVAHOME'] = 'D:/Java/bin'\n",
    "os.environ['STANFORD_PARSER'] = '/Applications/stanford-parser'\n",
    "os.environ['STANFORD_MODELS'] = '/Applications/stanford-parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "parser = CoreNLPParser(url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r\"\\w+\")\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "    \n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what distinction is undoubtedly permissible\n",
      "Clause: must be consulted to discover whether they allow quiet hunting or prohibit it altogether \n"
     ]
    }
   ],
   "source": [
    "query = \"What distinction is undoubtedly permissible?\"\n",
    "query = re.sub(r'[^\\w\\s]', '', query)\n",
    "print(\"Question:\", query.lower())\n",
    "result = next(parser.raw_parse((query).lower()))\n",
    "query_split = query.split(\" \")\n",
    "sub_clause_labels = ['NP', 'N', 'VP', 'PP']\n",
    "new_query = ''\n",
    "# print(result[0])\n",
    "\n",
    "if query_split[0].lower() in ['what', 'when', 'why', 'how', 'where', 'which', 'who']:\n",
    "        if subtree.label() in sub_clause_labels:\n",
    "            new_query += ' '.join(subtree.leaves()) + \" \"\n",
    "else:\n",
    "    for subtree in result:\n",
    "        if subtree.label() in sub_clause_labels:\n",
    "            new_query += ' '.join(subtree.leaves()) + \" \"\n",
    "\n",
    "if len(new_query) == 0:\n",
    "    new_query += query.lower()\n",
    "    \n",
    "print(\"Clause:\", new_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "context =\"Nevertheless, although a distinction between lawful and unlawful hunting is undoubtedly permissible, it is certain that a bishop can absolutely prohibit all hunting to the clerics of his diocese, as was done by synods at Milan, Avignon, LiÃ¨ge, Cologne, and elsewhere. Benedict XIV (De synodo diÅ“ces., l. II, c. x) declared that such synodal decrees are not too severe, as an absolute prohibition of hunting is more conformable to the ecclesiastical law. In practice, therefore, the synodal statutes of various localities must be consulted to discover whether they allow quiet hunting or prohibit it altogether.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = context.lower()\n",
    "context_split = re.split('[!#$%&\\()*+-./:;<=>?@[\\\\]^_`{|}~]', context)\n",
    "for i in range(len(context_split)):\n",
    "    context_split[i] = context_split[i].strip()\n",
    "    \n",
    "context_split = [x for x in context_split if len(x)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['although a distinction between lawful and unlawful hunting is undoubtedly permissible', 'it is certain that a bishop can absolutely prohibit all hunting to the clerics of his diocese', 'as was done by synods at milan', 'and elsewhere', 'declared that such synodal decrees are not too severe', 'as an absolute prohibition of hunting is more conformable to the ecclesiastical law', 'the synodal statutes of various localities must be consulted to discover whether they allow quiet hunting or prohibit it altogether']\n"
     ]
    }
   ],
   "source": [
    "clauses = []\n",
    "labels = ['SBAQ', 'S', 'SQ', 'SBAR', 'FRAG', 'SBARQ']\n",
    "for cs in context_split:\n",
    "    result = next(parser.raw_parse(cs))\n",
    "    if result[0].label() in labels:\n",
    "        clauses.append(' '.join(result[0].leaves()))\n",
    "print(clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question: What distinction is undoubtedly permissible\n",
      "\n",
      "Model's Answer: a distinction between lawful and unlawful hunting is undoubtedly permissible\n"
     ]
    }
   ],
   "source": [
    "clauses_dictionary = {}\n",
    "clause_counter = 0\n",
    "np_dictionary = {}\n",
    "\n",
    "for clause in clauses:\n",
    "    result = next(parser.raw_parse(clause))\n",
    "    if result[0].label() in labels:\n",
    "        clause_counter += 1\n",
    "        clauses_dictionary[str(clause_counter)] = {}\n",
    "        clauses_dictionary[str(clause_counter)][str(clause_counter) + \"_\" + \"clause\"] = ' '.join(result[0].leaves())\n",
    "        np_dictionary[str(clause_counter) + \"_NVP_\" + \"clause\"] = ''\n",
    "        inner_clause1 = 0\n",
    "        \n",
    "        for subtree in result[0]:\n",
    "            if subtree.label() in labels:\n",
    "                inner_clause1 += 1\n",
    "                clauses_dictionary[str(clause_counter)][str(clause_counter) + \"_\" + str(inner_clause1) + \"_\" + \"clause\"] = ' '.join(subtree.leaves())\n",
    "                np_dictionary[str(clause_counter) + \"_\" + str(inner_clause1) + \"_NVP_\" + \"clause\"] = ''\n",
    "                \n",
    "                inner_clause2 = 0\n",
    "                for subtree2 in subtree:\n",
    "                    if subtree2.label() in labels:\n",
    "                        inner_clause2 += 1\n",
    "                        clauses_dictionary[str(clause_counter)][str(clause_counter) + \"_\" + str(inner_clause1) + \"_\" + str(inner_clause2) + \"_\" + \"clause\"] = ' '.join(subtree2.leaves())\n",
    "                        np_dictionary[str(clause_counter) + \"_\" + str(inner_clause1) + \"_\" + str(inner_clause2) + \"_NVP_\" + \"clause\"] = \"\"\n",
    "                        \n",
    "                        for subtree3 in subtree2:\n",
    "                            np_dictionary[str(clause_counter) + \"_\" + str(inner_clause1) + \"_\" + str(inner_clause2) + \"_NVP_\" + \"clause\"] += ' '.join(subtree3.leaves()) + \" \"\n",
    "                    \n",
    "                    elif subtree2.label() in sub_clause_labels:\n",
    "                        np_dictionary[str(clause_counter) + \"_\" + str(inner_clause1) + \"_NVP_\" + \"clause\"] += ' '.join(subtree2.leaves()) + \" \"\n",
    "                    \n",
    "            elif subtree.label() in sub_clause_labels:\n",
    "                np_dictionary[str(clause_counter) + \"_NVP_\" + \"clause\"] += ' '.join(subtree.leaves()) + \" \"\n",
    "\n",
    "print(\"Original question:\", query)\n",
    "print()\n",
    "question_np = new_query\n",
    "question_vector = text_to_vector(question_np)\n",
    "cosine_np_dict = {}\n",
    "cosine_np_dict_lemm = {}\n",
    "\n",
    "# print(clauses_dictionary)\n",
    "# print()\n",
    "# print(np_dictionary)\n",
    "question_np_lemm = text = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in question_np.split() if word not in stop_words])\n",
    "question_vector_lemm = text_to_vector(question_np_lemm)\n",
    "\n",
    "for np in np_dictionary:\n",
    "    np_vector = text_to_vector(np_dictionary[np])\n",
    "    cosine_np_dict[np] = get_cosine(question_vector, np_vector)\n",
    "    \n",
    "    np_lemm = ' '.join([wordnet_lemmatizer.lemmatize(word) for word in np_dictionary[np].split() if word not in stop_words])\n",
    "    np_vector_lemm = text_to_vector(np_lemm)\n",
    "    cosine_np_dict_lemm[np] = get_cosine(question_vector_lemm, np_vector_lemm)\n",
    "\n",
    "import operator\n",
    "max_clause_id, max_sim = max(cosine_np_dict.items(), key=operator.itemgetter(1))[0], max(cosine_np_dict.items(), key=operator.itemgetter(1))[1]\n",
    "\n",
    "if max_sim >= 0.2:\n",
    "    clause_id = max_clause_id[:max_clause_id.find(\"NVP\")-1]\n",
    "    first_clause_id = clause_id[:clause_id.find(\"_\")]\n",
    "    \n",
    "    answer = clauses_dictionary[first_clause_id][clause_id + \"_clause\"]\n",
    "    answer_split = answer.split(\" \")\n",
    "    if answer_split[0] in [\"and\", 'but', 'or', 'nor', 'after', 'before', 'although']:\n",
    "        answer_split.pop(0)\n",
    "    answer_return = \" \".join(answer_split)\n",
    "    print(\"Model's Answer:\", answer_return)\n",
    "else:\n",
    "    print(\"Unable to retrieve answer\")\n",
    "\n",
    "# max_clause_id_lemm, max_sim_lemm = max(cosine_np_dict_lemm.items(), key=operator.itemgetter(1))[0], max(cosine_np_dict_lemm.items(), key=operator.itemgetter(1))[1]\n",
    "\n",
    "# if max_sim_lemm >= 0.25:\n",
    "#     clause_id_lemm = max_clause_id_lemm[:max_clause_id_lemm.find(\"NVP\")-1]\n",
    "\n",
    "#     answer_lemm = clauses_dictionary[clause_id_lemm][clause_id_lemm + \"_clause\"]\n",
    "#     answer_split_lemm = answer_lemm.split(\" \")\n",
    "#     if answer_split_lemm[0] in [\"and\", 'but', 'or', 'nor', 'after', 'before', 'although']:\n",
    "#         answer_split_lemm.pop(0)\n",
    "#     answer_return_lemm = \" \".join(answer_split_lemm)\n",
    "#     print(\"Answer:\", answer_return_lemm)\n",
    "# else:\n",
    "#     print(\"Unable to retrieve answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
